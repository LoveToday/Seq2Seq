{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A GRU based Encoder which encodes the input vector to a vector while also returing the output for each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_encoder(vocab_size, embedding_dim, enc_units, max_sentence_length):\n",
    "    \"\"\"\n",
    "    Creates an encoder with the necessary vocabulary size, embedding dimension and encoding units\n",
    "    The model is very simple:\n",
    "    \n",
    "    Input -> Embedding -> GRU Layer -> Hidden Vector output which is to be passed to decoder\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.layers.Input((max_sentence_length, ))\n",
    "    embed = tf.keras.layers.Embedding(vocab_size, embedding_dim)(inputs)\n",
    "    output, state = tf.keras.layers.GRU(enc_units, \n",
    "                                        return_sequences=True, \n",
    "                                        return_state=True,\n",
    "                                        reset_after = True,\n",
    "                                        recurrent_initializer='glorot_uniform')(embed)\n",
    "    encoder = tf.keras.models.Model(inputs, [output, state])\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Create a layer that implements Bahadanau attention mechanism\n",
    "    More details at https://www.tensorflow.org/tutorials/text/nmt_with_attention\n",
    "    \"\"\"\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        self.R = tf.keras.layers.Dropout(0.25)\n",
    "        \n",
    "    def call(self, query, values):\n",
    "        # hidden_size = num_units\n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "        \n",
    "        score = self.R(score)  # perform regularization\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_decoder(vocab_size, embedding_dim, enc_units, dec_units, max_sentence_length):\n",
    "    \"\"\"\n",
    "    Implements a simple Decoder model. Network is as follows:\n",
    "    \n",
    "    Encoder Output                  Hidden State of Encoder                 Decoder input of previous word\n",
    "              \\                         /                                            |                                                      \n",
    "                  Bahadanau Attetion                                             Embedding\n",
    "                        |                                                            | \n",
    "                    Context Vector                                                  /\n",
    "                                 \\                                                 /\n",
    "                                            Concatenated Input\n",
    "                                                 |\n",
    "                                             GRU Cell\n",
    "                                                 |\n",
    "                                            Dense Layer\n",
    "                                                 |\n",
    "                                Predicted probabilities on the vocabulary\n",
    "        \n",
    "    \"\"\"\n",
    "    enc_output = tf.keras.layers.Input((max_sentence_length, enc_units, ))\n",
    "    hidden = tf.keras.layers.Input((enc_units, ))\n",
    "    context_vector = BahdanauAttention(dec_units)(hidden, enc_output)\n",
    "    \n",
    "    dec_input = tf.keras.layers.Input((1, ))\n",
    "    dec_embed = tf.keras.layers.Embedding(vocab_size, embedding_dim)(dec_input)\n",
    "    \n",
    "    context_expand = tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, 1))(context_vector)\n",
    "    full_context = tf.keras.layers.Concatenate(axis = -1)([context_expand, dec_embed])\n",
    "    output, state = tf.keras.layers.GRU(dec_units, \n",
    "                                        return_sequences=True, \n",
    "                                        return_state=True,\n",
    "                                        reset_after = True,\n",
    "                                        recurrent_initializer='glorot_uniform')(full_context)\n",
    "    flat_output = tf.keras.layers.Flatten()(output)\n",
    "    final = tf.keras.layers.Dense(vocab_size, activation = 'softmax')(flat_output)\n",
    "    \n",
    "    decoder = tf.keras.models.Model([enc_output, hidden, dec_input], [final, state])\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(target, pred):\n",
    "    \"\"\"\n",
    "    Returns the total loss over all batch, using categorical crossentropy\n",
    "    \"\"\"\n",
    "    # 求和\n",
    "    return tf.math.reduce_sum(tf.keras.losses.sparse_categorical_crossentropy(target, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Making the necessary imports\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "import glob\n",
    "import argparse\n",
    "import os\n",
    "from keras.preprocessing.text import tokenizer_from_json\n",
    "# This will force execute tensorflow in eager execution mode \n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_lang_path = './processed_data_en-fra/inp_lang.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language Loaded...\n"
     ]
    }
   ],
   "source": [
    "# load the tokenziers\n",
    "# The JSON files contain the encoding corresponding to each word in the input and output lines (done in preprocess.py)\n",
    "with open(inp_lang_path, 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "    inp_lang = tokenizer_from_json(json_data)\n",
    "    f.close()\n",
    "\n",
    "print('Input Language Loaded...') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ_lang_path = './processed_data_en-fra/targ_lang.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Language Loaded...\n"
     ]
    }
   ],
   "source": [
    "with open(targ_lang_path, 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "    targ_lang = tokenizer_from_json(json_data)\n",
    "    f.close()\n",
    "\n",
    "print('Target Language Loaded...') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_npz = './processed_data_en-fra/data.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile = np.load(data_npz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121935"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(npzfile['arr_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "BUFFER_SIZE = len(npzfile['arr_0'])\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(npzfile['arr_0'])#BATCH_SIZE\n",
    "embedding_dim = 128\n",
    "units = 256\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "max_sentence_length = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset into memory...\n"
     ]
    }
   ],
   "source": [
    "# create tensorflow dataset pipeline for faster processing\n",
    "dataset = tf.data.Dataset.from_tensor_slices((npzfile['arr_0'], npzfile['arr_1'])).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "print('Loaded dataset into memory...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 15)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 15, 128)           1898240   \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    [(None, 15, 256), (None,  296448    \n",
      "=================================================================\n",
      "Total params: 2,194,688\n",
      "Trainable params: 2,194,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create encoder from Chatbot class\n",
    "encoder = create_encoder(vocab_inp_size, embedding_dim, units, max_sentence_length)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 15, 256)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bahdanau_attention (BahdanauAtt (None, 256)          131841      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1, 256)       0           bahdanau_attention[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 128)       3800448     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1, 384)       0           lambda[0][0]                     \n",
      "                                                                 embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     [(None, 1, 256), (No 493056      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 256)          0           gru_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 29691)        7630587     flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 12,055,932\n",
      "Trainable params: 12,055,932\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create decoder from Chatbot class\n",
    "decoder = create_decoder(vocab_tar_size, embedding_dim, units, units, max_sentence_length)\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are lots of parameters, so more training would yield better results\n",
    "optimizer = tf.keras.optimizers.Adam(1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the training step function that performs the optimization\n",
    "@tf.function\n",
    "def train_step(inp, targ):\n",
    "    loss = 0\n",
    "    # Firstly <start> is passed to the decoder to begin the process of teacher forcing\n",
    "    # Check out this article https://machinelearningmastery.com/teacher-forcing-for-recurrent-neural-networks/\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp)  # pass the input to the encoder, get encoder_output and state\n",
    "        dec_hidden = enc_hidden   # set the decoder hidden state same as encoder final state\n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden = decoder([enc_output, dec_hidden, dec_input])\n",
    "\n",
    "            loss += loss_func(targ[:, t], predictions)\n",
    "\n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_weight(files):\n",
    "    files.sort(key=lambda x:float(x[len(files)-9:-3]))\n",
    "    return files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epoch(files):\n",
    "    files.sort(key=lambda x:int(x.split(\"_\")[2][6:]), reverse=True)\n",
    "    eno = files[0].split(\"_\")[2][6:]\n",
    "    return int(eno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here you have the training step\n",
    "def training(EPOCHS, name, resume = False):\n",
    "    show_output = 10\n",
    "    start=0\n",
    "    if resume:\n",
    "        enc_models = glob.glob(f'models_'+name+'/encoder_*.h5', recursive=True)\n",
    "        dec_models = glob.glob(f'models_'+name+'/decoder_*.h5', recursive=True)\n",
    "        encoder.load_weights(best_weight(enc_models))\n",
    "        decoder.load_weights(best_weight(dec_models))\n",
    "        start = get_epoch(enc_models)\n",
    "        print(\"Encoder Model: \",best_weight(enc_models))\n",
    "        print(\"Decoder Model: \",best_weight(dec_models))\n",
    "        print(\"Weights Loaded\")\n",
    "        print(\"Resuming from Epoch\", start+1)\n",
    "\n",
    "    if not os.path.exists('models_'+name):\n",
    "        os.mkdir('models_'+name)\n",
    "        \n",
    "    for epoch in range(start, EPOCHS):\n",
    "        print('=' * 80)\n",
    "        print('EPOCH: ', epoch+1)\n",
    "        total_loss = 0\n",
    "\n",
    "        for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "            batch_loss = train_step(inp, targ)\n",
    "            total_loss += batch_loss\n",
    "\n",
    "            if batch % show_output == 0:\n",
    "                print(str(batch/show_output) + '\\t\\t Loss: ' + str(batch_loss))\n",
    "\n",
    "        print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch))\n",
    "\n",
    "        r_loss = str(total_loss / steps_per_epoch)\n",
    "        r_loss = r_loss[10:16]\n",
    "        if epoch % 50 == 0:\n",
    "            # after training save the weights\n",
    "            encoder.save_weights('models_'+name+'/encoder_epoch-{}_loss-{}.h5'.format(str(epoch+1), str(r_loss)))\n",
    "            decoder.save_weights('models_'+name+'/decoder_epoch-{}_loss-{}.h5'.format(str(epoch+1), str(r_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when performing training for first time, First_time = True, else First_time = False\n",
    "training(1000, 'en-fra', resume = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
